# ğŸ§  Adaptive Online Learning - Real-time Anomaly Detection

## ğŸ¯ Overview

This adaptive system uses **online learning** to train the transformer on YOUR specific log patterns:

### 3-Phase Workflow:

1. **Phase 1 - Warmup (0-50k logs)**
   - âœ… Rule-based detection active
   - ğŸ“Š Isolation Forest collecting baseline (not detecting yet)
   - âŒ Transformer inactive (collecting training data)
   - Purpose: Gather normal baseline from your actual log traffic

2. **Phase 2 - Training (Background)**
   - ğŸ”„ Isolation Forest training on collected 50k samples
   - ğŸ”„ Transformer training on collected 50k logs
   - âœ… Rule-based continues detecting
   - Purpose: Adapt both ML models to your log domain

3. **Phase 3 - Full Ensemble (After training)**
   - âœ… Rule-based active
   - âœ… **Isolation Forest active** (domain-adapted)
   - âœ… **Transformer active** (domain-adapted)
   - Purpose: Maximum detection accuracy with all 3 models

## ğŸš€ Quick Start

### 1. Test the Adaptive System

```bash
cd realtime_anomaly_detection
python test_adaptive.py
```

Expected output:
```
PHASE 1: WARMUP (First 100 logs)
  Active models: Rule-based only
  [100/100] âœ“ Warmup complete! Templates collected: 4

PHASE 2: TRAINING MODELS
  ğŸ”„ Training Isolation Forest on 100 samples...
  âœ… Isolation Forest trained successfully!
  
  Epoch 1/3 - Loss: 1.5015
  Epoch 2/3 - Loss: 0.6219
  Epoch 3/3 - Loss: 0.2664
  âœ“ Training complete!

PHASE 3: FULL ENSEMBLE DETECTION
  Active models: Rule-based + Isolation Forest + Transformer
  ğŸ”´ DETECTED - XSS attack
    Rule-based: âœ“ ['xss']
    Iso Forest: âœ“ (score: 0.83)
    Transformer: âœ“ (score: 0.73)
```

### 2. Start Adaptive API Server

**Terminal 1:**
```bash
cd realtime_anomaly_detection/api
python server_adaptive.py
```

You'll see:
```
======================================================================
ADAPTIVE ENSEMBLE DETECTOR - ONLINE LEARNING MODE
======================================================================
Phase 1: Processing 50,000 logs with Rule-based + Isolation Forest
Phase 2: Training Transformer in background
Phase 3: Full ensemble detection after training
======================================================================
```

### 3. Stream Logs for Adaptive Learning

**Terminal 2:**
```bash
cd realtime_anomaly_detection/streaming

# Stream all logs - will trigger training after 50k
python log_streamer.py \
  --log-file ../../data/apache_logs/synthetic_nodejs_apache_10k.log \
  --delay 0.01
```

**Real-time Output:**
```
[NORMAL ] [WARMUP:1,245] Score: 0.300 GET / 200
[NORMAL ] [WARMUP:24,567] Score: 0.300 GET /api/users 200
[NORMAL ] [WARMUP:50,000] Score: 0.300 GET /favicon.ico 200

ğŸ”„ ISOLATION FOREST TRAINING STARTED
  Samples collected: 50,000
  Features: 14 dimensions

ğŸ”„ TRANSFORMER TRAINING STARTED (Background)
  Templates collected: 23,450
  Training sequences: 48,920

[NORMAL ] [TRAINING...] Score: 0.300 GET / 200
[ANOMALY] [TRAINING...] Score: 1.000 [R:xss] GET /search?q=<script>...

âœ… ISOLATION FOREST TRAINING COMPLETE
âœ… TRANSFORMER TRAINING COMPLETE
  Vocabulary: 23,450 templates
  Threshold: 5.82

[NORMAL ] [FULL-3M] Score: 0.214 [I:0.62 | T:2.34] GET /api/users 200
[ANOMALY] [FULL-3M] Score: 0.956 [R:xss | I:8.45 | T:15.32] GET /search?q=<script>...
```

### Phase Indicators:
- `[WARMUP:N]` - Collecting baseline data (N = logs processed) - **Only Rule-based active**
- `[TRAINING...]` - ML models training in background - **Rule-based only**
- `[FULL-3M]` - All 3 models active (Full ensemble) - **Rule + Iso + Transformer**

## ğŸ”§ Configuration

### Adjust Warmup Period

Edit `server_adaptive.py`:
```python
detector = AdaptiveEnsembleDetector(
    model_dir=model_dir,
    warmup_logs=50000,  # Change this (default: 50,000)
    window_size=20,
    device='cpu'
)
```

Recommendations:
- **Small datasets** (<10k logs): `warmup_logs=1000`
- **Medium datasets** (10k-100k): `warmup_logs=5000`
- **Large datasets** (>100k): `warmup_logs=50000`
- **Production**: `warmup_logs=100000`

### Transformer Architecture

Edit `models/adaptive_detector.py` â†’ `train_transformer_background()`:
```python
self.transformer = TemplateTransformer(
    vocab_size=vocab_size,
    d_model=256,       # Model dimension (default: 256)
    n_heads=8,         # Attention heads (default: 8)
    n_layers=4,        # Transformer layers (default: 4)
    ffn_dim=1024,      # FFN dimension (default: 1024)
    dropout=0.1
)
```

For faster training:
- Reduce `n_layers` to 2
- Reduce `d_model` to 128
- Reduce `epochs` to 2

For better accuracy:
- Increase `n_layers` to 6
- Increase `d_model` to 512
- Increase `epochs` to 5

## ğŸ“Š API Endpoints

### Check Learning Status
```bash
curl http://localhost:8000/status
```

Response:
```json
{
  "logs_processed": 25430,
  "warmup_target": 50000,
  "warmup_complete": false,
  "training_in_progress": false,
  "transformer_ready": false,
  "vocabulary_size": 12456,
  "training_sequences": 24980,
  "active_models": {
    "rule_based": true,
    "isolation_forest": true,
    "transformer": false
  },
  "phase": "warmup"
}
```

### Health Check
```bash
curl http://localhost:8000/health
```

Response:
```json
{
  "status": "healthy",
  "phase": "ensemble",
  "logs_processed": 75234,
  "transformer_ready": true,
  "active_models": 3
}
```

## ğŸ“ How It Works

### 1. Template Collection (Warmup Phase)

For each incoming log:
1. Parse Apache log format
2. Normalize to template (e.g., `GET /api/users?id=123` â†’ `GET /api/users HTTP/1.1 200`)
3. Build vocabulary of unique templates
4. Collect sequences (windows of 20 templates per IP)
5. Collect statistical features for Isolation Forest
6. **Only Rule-based detection active** (no false positives from untrained ML models)

### 2. Background Training

After 50k logs:
1. **Train Isolation Forest**:
   - 50,000 feature vectors collected
   - 14 dimensions per sample (request_count, error_rate, status codes, etc.)
   - Learns normal baseline from YOUR traffic patterns
   - Contamination: 10% (expects 10% anomalies)

2. **Train Transformer**:
   - Extract vocabulary (e.g., 23,450 unique templates)
   - Create training dataset (e.g., 48,920 sequences)
   - Initialize Transformer with domain-specific vocab
   - Train for 3 epochs (quick fine-tuning)
   - Calculate adaptive threshold (95th percentile of training scores)
   - Save trained model to `artifacts/ensemble_model_export/online_transformer.pt`

### 3. Full Ensemble Detection

For each log after training:
1. **Rule-based**: Pattern matching (SQL, XSS, path traversal, etc.)
2. **Isolation Forest**: Statistical anomaly on HTTP features (domain-adapted!)
3. **Transformer**: Sequence behavioral analysis (domain-adapted!)
4. **Ensemble Vote**: Weighted combination
   - Rule: weight = confidence (0.4-1.0)
   - Isolation Forest: weight = 0.6
   - Transformer: weight = 0.7
   - Decision: anomaly if weighted_score > 0.5

## ğŸ’¡ Advantages vs Static Model

### Static Model (Original):
- âŒ Trained on generic Apache logs
- âŒ May not match your domain (Node.js vs PHP vs Python)
- âŒ Fixed vocabulary (23,705 templates from training data)
- âŒ High threshold (12.22) may miss domain-specific anomalies

### Adaptive Model:
- âœ… Trains on YOUR logs
- âœ… Adapts to YOUR application patterns
- âœ… Builds vocabulary from YOUR endpoints
- âœ… Calculates threshold from YOUR baseline
- âœ… Better detection for YOUR specific threats

## ğŸ“ˆ Performance Comparison

### Static Model on nodejs logs:
- Vocabulary coverage: 11%
- Transformer detections: 0
- Active models: Rule + Iso only
- F1-Score: 0.630

### Adaptive Model on nodejs logs:
- Vocabulary coverage: 100% (by design)
- Transformer detections: Active after 50k
- Active models: All 3
- F1-Score: Expected 0.75+ (domain-adapted)

## ğŸ”„ Production Deployment

### Recommended Workflow:

1. **Cold Start** (First deployment):
   ```bash
   # Start adaptive API
   python server_adaptive.py
   
   # Stream historical logs (if available)
   python log_streamer.py --log-file historical_logs.log --delay 0.001
   ```

2. **Warm Start** (After initial training):
   - Trained model saved to `artifacts/ensemble_model_export/online_transformer.pt`
   - On next startup, model loads from checkpoint
   - Continue detecting with all 3 models immediately

3. **Continuous Learning** (Future enhancement):
   - Periodically retrain on last N days of logs
   - Update threshold based on recent baseline
   - Drift detection and model refresh

## ğŸ› Troubleshooting

### Training takes too long
- Reduce `warmup_logs` from 50000 to 10000
- Reduce transformer `n_layers` from 4 to 2
- Reduce `epochs` from 3 to 2

### Out of memory during training
- Reduce batch_size from 64 to 32
- Reduce `d_model` from 256 to 128
- Process fewer sequences (filter by unique IPs)

### Low detection rate after training
- Lower the threshold multiplier (95th â†’ 90th percentile)
- Increase transformer weight in ensemble (0.7 â†’ 0.9)
- Train on more logs (50k â†’ 100k)

## ğŸ“ Files Created

```
realtime_anomaly_detection/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ ensemble_detector.py       # Original static model
â”‚   â””â”€â”€ adaptive_detector.py       # NEW: Adaptive online learning
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ server.py                  # Original static API
â”‚   â”œâ”€â”€ server_adaptive.py         # NEW: Adaptive API
â”‚   â””â”€â”€ start_adaptive.sh          # NEW: Startup script
â”œâ”€â”€ test_adaptive.py               # NEW: Test adaptive system
â””â”€â”€ ADAPTIVE_LEARNING.md           # NEW: This guide
```

## ğŸ¯ Next Steps

1. **Test with your logs**:
   ```bash
   python log_streamer.py --log-file YOUR_LOGS.log
   ```

2. **Monitor training progress**:
   ```bash
   watch -n 1 curl -s http://localhost:8000/status
   ```

3. **Compare static vs adaptive**:
   - Run both servers on different ports
   - Stream same logs to both
   - Compare detection rates

4. **Fine-tune for production**:
   - Adjust warmup_logs based on traffic volume
   - Tune ensemble weights for your priorities
   - Add custom rule patterns for your attacks

---

**ğŸš€ Ready for adaptive online learning!**

The system will automatically adapt to your log domain and improve detection accuracy over time.
