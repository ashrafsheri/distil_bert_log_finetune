# Fine-tuning configuration for OpenStack log anomaly modeling
seed: 1337

base_checkpoint_dir: artifacts/logbert-mlm-hdfs

sequence:
  max_length: 256
  mlm_probability: 0.15
  pad_to_multiple_of: 8

training:
  epochs: 5
  patience: 2
  min_delta: 5.0e-4
  train_batch_size_per_device: 16
  eval_batch_size_per_device: 32
  grad_accumulation_steps: 4
  max_grad_norm: 1.0
  checkpoint_fraction: 0.25  # fraction of an epoch between checkpoints
  log_every: 50

optimizer:
  type: adamw
  lr: 5.0e-6
  weight_decay: 0.01
  betas: [0.9, 0.999]
  eps: 1.0e-8
  scheduler: cosine
  warmup_steps: 1000

precision:
  mixed_precision: fp16

replay:
  enabled: true
  ratio: 0.1
  source_parquet: artifacts/datasets/hdfs_train.parquet
  sampling: random

checkpointing:
  output_dir: artifacts/logbert-mlm-os

metrics:
  required:
    f1: 0.70
    roc_auc: 0.85
    pr_auc: 0.60
  curve_points: 200

artifacts:
  tokenizer_dir: artifacts/tokenizer
  metrics_dir: artifacts/metrics/openstack
  eval_dir: artifacts/eval
  run_config_path: artifacts/logbert-mlm-os/run_config.json

logging:
  throughput_ema_beta: 0.9
  log_gpu_memory: true
